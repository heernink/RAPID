{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Data2/hm22/Faster-RCNN-with-torchvision-master'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8813,
     "status": "ok",
     "timestamp": 1660587334557,
     "user": {
      "displayName": "김희원",
      "userId": "13562236615599718077"
     },
     "user_tz": -540
    },
    "id": "LczAfF1Whhkm"
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import dataset.transforms as T\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt ###add\n",
    "#%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from dataset.coco_utils import get_coco, get_coco_kp\n",
    "from rapid import train_one_epoch, evaluate\n",
    "from dataset.group_by_aspect_ratio import GroupedBatchSampler, create_aspect_ratio_groups\n",
    "import argparse\n",
    "import torchvision\n",
    "\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1660587338568,
     "user": {
      "displayName": "김희원",
      "userId": "13562236615599718077"
     },
     "user_tz": -540
    },
    "id": "GOy8uCsehNBD"
   },
   "outputs": [],
   "source": [
    "data_path = '/Data2/hm22/Faster-RCNN-with-torchvision-master/data/coco/'\n",
    "model_name = 'fasterrcnn_resnet50_fpn_v2'\n",
    "dataset_name = 'coco'\n",
    "device_type = 'cuda'\n",
    "batch_size = 1 #8\n",
    "epochs = 20\n",
    "workers = 1\n",
    "lr = 0.02\n",
    "momentum = 0.9 \n",
    "weight_decay = 0.0001\n",
    "print_freq = 20\n",
    "lr_step_size = 8\n",
    "lr_steps = [8,11]\n",
    "lr_gamma = 0.1\n",
    "resume = ''\n",
    "test_only = True\n",
    "output_dir = '/Data2/hm22/Faster-RCNN-with-torchvision-master/result'\n",
    "aspect_ratio_group_factor = 0\n",
    "pretrained = True\n",
    "distributed = False\n",
    "parallel = False\n",
    "world_size =1\n",
    "dist_url = 'env://'\n",
    "attack = True ########################################## ATTACK OR NOT (default = False)\n",
    "dpatch = False ########################################## DPATCH OR Robust-DPATCH (default = False = Robust-DPATCH)\n",
    "multi = True ########################################## SINGLE OR MULTI (default = False = Single patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1660587345281,
     "user": {
      "displayName": "김희원",
      "userId": "13562236615599718077"
     },
     "user_tz": -540
    },
    "id": "AyZV8yMDiQC_"
   },
   "outputs": [],
   "source": [
    "def get_dataset(name, image_set, transform):\n",
    "    paths = {\n",
    "        \"coco\": ('/Data2/hm22/Faster-RCNN-with-torchvision-master/data/coco/', get_coco, 91),\n",
    "        \"coco_kp\": ('/datasets01/COCO/022719/', get_coco_kp, 2)\n",
    "    }\n",
    "    p, ds_fn, num_classes = paths[name]\n",
    "\n",
    "    ds = ds_fn(p, image_set=image_set, transforms=transform)\n",
    "    return ds, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 334,
     "status": "ok",
     "timestamp": 1660587377189,
     "user": {
      "displayName": "김희원",
      "userId": "13562236615599718077"
     },
     "user_tz": -540
    },
    "id": "2hqel50WaHvn"
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 29 23:52:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:1A:00.0 Off |                    0 |\n",
      "| 30%   28C    P8    27W / 300W |   3797MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    On   | 00000000:1B:00.0 Off |                    0 |\n",
      "| 40%   67C    P2   159W / 300W |  22951MiB / 46068MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:1D:00.0 Off |                    0 |\n",
      "| 33%   42C    P2    74W / 260W |   3899MiB / 46080MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:1E:00.0 Off |                    0 |\n",
      "| 33%   45C    P2    65W / 260W |   7849MiB / 46080MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                    0 |\n",
      "| 47%   70C    P2   223W / 260W |  37857MiB / 46080MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Quadro RTX 8000     On   | 00000000:3E:00.0 Off |                    0 |\n",
      "| 46%   70C    P2   222W / 260W |   4343MiB / 46080MiB |     79%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GIOEzSXghRY2"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    import os\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print ('Available devices ', torch.cuda.device_count())\n",
    "    \n",
    "    GPU_NUM = 5 # 원하는 GPU 번호 입력\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "    \n",
    "    print('Device', device)\n",
    "    \n",
    "    if output_dir:\n",
    "        utils.mkdir(output_dir)    \n",
    "\n",
    "    # Data loading\n",
    "    print(\"Loading data\")\n",
    "    dataset, num_classes = get_dataset(dataset_name, \"train\", get_transform(train=True))\n",
    "    dataset_test, _ = get_dataset(dataset_name, \"val\", get_transform(train=False)) \n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"Creating data loaders\")\n",
    "    if distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(dataset_test)\n",
    "    else:\n",
    "        train_sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
    "\n",
    "    if aspect_ratio_group_factor >= 0:\n",
    "        group_ids = create_aspect_ratio_groups(dataset, k=aspect_ratio_group_factor)\n",
    "        train_batch_sampler = GroupedBatchSampler(train_sampler, group_ids, batch_size)\n",
    "    else:\n",
    "        train_batch_sampler = torch.utils.data.BatchSampler(\n",
    "            train_sampler, batch_size, drop_last=True)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_sampler=train_batch_sampler, num_workers=workers,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=batch_size,\n",
    "        sampler=test_sampler, num_workers=workers,\n",
    "        collate_fn=utils.collate_fn)\n",
    "    \n",
    "\n",
    "    # Print shape of the first batch of images in the data loader\n",
    "    #images, _ = next(iter(data_loader_test))\n",
    "    #for image in images:\n",
    "    #    print(\"Image shape:\", image.shape)\n",
    "\n",
    "    \n",
    "    # Model creating\n",
    "    print(\"Creating model\")\n",
    "    # model = models.__dict__[model](num_classes=num_classes, pretrained=pretrained)   \n",
    "    model = torchvision.models.detection.__dict__[model_name](num_classes=num_classes,\n",
    "                                                              pretrained=pretrained)\n",
    "\n",
    "    device = torch.device(device_type)\n",
    "    model.to(device)\n",
    "\n",
    "    # Distribute\n",
    "    model_without_ddp = model\n",
    "    if distributed:\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "        model_without_ddp = model.module    \n",
    "\n",
    "    # Parallel\n",
    "    if parallel:\n",
    "        print('Training parallel')\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        model_without_ddp = model.module\n",
    "\n",
    "    # Optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=lr_steps, gamma=lr_gamma)\n",
    "\n",
    "    # Resume training\n",
    "    if resume:\n",
    "        print('Resume training')\n",
    "        checkpoint = torch.load(resume, map_location='cpu')\n",
    "        model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "\n",
    "    if test_only:\n",
    "        evaluate(model, data_loader_test, device=device, dpatch=dpatch, attack=attack, multi=multi, defense=defense)\n",
    "        return\n",
    "\n",
    "    # Training\n",
    "    print('Start training')\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq)\n",
    "        lr_scheduler.step()\n",
    "        if output_dir:\n",
    "            utils.save_on_master({\n",
    "                'model': model_without_ddp.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict()\n",
    "                },\n",
    "                os.path.join(output_dir, 'model_{}.pth'.format(epoch)))\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        #evaluate(model, data_loader_test, device=device, dpatch=False, attack=True, multi=True, defense=True)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNhwkERItU68pvyy+cbsZ97",
   "collapsed_sections": [],
   "mount_file_id": "17VtVxcJBq7CUMfsOzlg8uuhuMXWgsCz1",
   "name": "Faster_RCNN_pytorch_notebook_training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
